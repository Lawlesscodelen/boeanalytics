{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelo para clasificar el BOE v0.2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Ly2C2FviPs6J"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LkqgiVeIk8z",
        "colab_type": "text"
      },
      "source": [
        "# Modelo para clasificar el BOE\n",
        "\n",
        "Una vez que hayamos clasificado los 2000 BOEs que se encuentran en el fichero \"[BOEs juntos](https://drive.google.com/open?id=1zz6F-fr1d-FHAxeZWWN2ZNgtexC139eQ-nFRV3BXLUk)\".\n",
        "\n",
        "Este desarrollo está basado parcialmente en los siguientes papers:\n",
        "1. https://medium.com/data-from-the-trenches/text-classification-the-first-step-toward-nlp-mastery-f5f95d525d73\n",
        "2. https://machinelearningmastery.com/load-machine-learning-data-python/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDG-3AK4Jf2U",
        "colab_type": "text"
      },
      "source": [
        "#1. Cargamos las bibliotecas que son necesarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtQjnyy8Jbpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nos ayudará a vectorizar los textos\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Biblioteca de Expresiones Regulares. Nos ayudará a limpiar el texto\n",
        "import re\n",
        "\n",
        "# Para importar y poder trabajar con los CSV\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "!pip install -U nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESSdeVLyLx5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Para esta iteracción vamos a usar el clasificador del Support Vector Machine\n",
        "# Otras opciones podrían ser\n",
        "# * Logistic Regressions\n",
        "# * Naive Bayes\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TE4E8LZNN1f",
        "colab_type": "text"
      },
      "source": [
        "#2. Creamos la función que nos ayudará a preparar los textos:\n",
        "* Quita espacios repetidos\n",
        "* Quitar caracteres extraños puntos, comas paréntesis, etc\n",
        "* Quita enters, tabuladores\n",
        "* Coloca todo en minúsculas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0q1KKuEN6hN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(serie):\n",
        "    \"\"\"\n",
        "    Adapta el texto dado.\n",
        "\n",
        "    Pasos:\n",
        "    - Quita signos de puntuación\n",
        "    - Pone todo en minúsculas\n",
        "    \"\"\"\n",
        "    \n",
        "    text = serie[0]\n",
        "        \n",
        "    # Quita los [\\], ['] y [\"]\n",
        "    text = re.sub(r\"\\\\\", \"\", text)    \n",
        "    text = re.sub(r\"\\'\", \"\", text)    \n",
        "    text = re.sub(r\"\\\"\", \"\", text)    \n",
        "    \n",
        "    # Pone todo en minúsculas\n",
        "    text = text.strip().lower()\n",
        "    \n",
        "    # Reemplaza todos los caracteres \"raros\" por espacios\n",
        "    filters='«»¡!\"\\'#$€%&()*+,-./:;<=>¿?@[\\\\]^_`{|}~\\t\\n'\n",
        "    translate_dict = dict((c, \" \") for c in filters)\n",
        "    translate_map = str.maketrans(translate_dict)\n",
        "    text = text.translate(translate_map)\n",
        "    serie[0] = text\n",
        "\n",
        "    return serie"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aukp_6G_eVTk",
        "colab_type": "text"
      },
      "source": [
        "# 3. Limpiamos el data set de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrLT1-4pecNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cargamos el CSV\n",
        "\n",
        "# Este la dirección en donde esta el fichero CSV\n",
        "filename = './BOES-juntos.csv'\n",
        "\n",
        "train = pd.read_csv(filename)\n",
        "\n",
        "# Hay veces que el excel tiene líneas en blanco\n",
        "# y estas son interpretadas como non/available N/A\n",
        "# el método dropna() del DataFrame de pandas los quita\n",
        "train = train.dropna()\n",
        "\n",
        "# Aplicamos la función de limpieza\n",
        "train = train.apply(clean_text, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McrthjyabrpH",
        "colab_type": "text"
      },
      "source": [
        "#4. Limpiamos el data set a procesar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeKuImQ3b05-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# Este la dirección en donde esta el fichero CSV\n",
        "compressed_filename = './t.csv.xz';\n",
        "\n",
        "# Al final, el fichero obtenido es u.csv\n",
        "filename = compressed_filename.replace(\".xz\", \"\")\n",
        "print(filename)\n",
        "\n",
        "# Si existe el fichero u.csv existe no lo descomprimimos\n",
        "if os.path.isfile(filename) == False:\n",
        "  # Descomprimir el CSV\n",
        "  !unxz $compressed_filename\n",
        "\n",
        "# Cargamos el CSV\n",
        "ts = time.time()\n",
        "process = pd.read_csv(filename, error_bad_lines=False, header=None)\n",
        "\n",
        "print (\"Hemos tardado \" + str(time.time() - ts) + \" segundos en cargar el CSV\")\n",
        "ts = time.time()\n",
        "\n",
        "# Hay veces que el excel tiene líneas en blanco\n",
        "# y estas son interpretadas como non/available N/A\n",
        "# el método dropna() del DataFrame de pandas los quita\n",
        "process = process.dropna()\n",
        "\n",
        "# Aplicamos la función de limpieza\n",
        "process = process.apply(clean_text, axis=1)\n",
        "\n",
        "print (\"Hemos tardado \" + str(time.time() - ts) + \" segundos en procesar CSV\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWRYG4TibOmC",
        "colab_type": "text"
      },
      "source": [
        "# 5. Cargamos el vectorizador\n",
        "### Junto con el listado de stopwords en español"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uLyeabkbdcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "vectorizer = pickle.load(open(\"BOE_fit_words.pickle\", \"rb\"))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRLGFGWNe2x8",
        "colab_type": "text"
      },
      "source": [
        "#5.1. Vectorizamos el conjunto de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEV99f6ce68c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorizamos el conjunto de datos de entrenamiento (train)\n",
        "\n",
        "training_features = vectorizer.transform(train[\"Texto\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qP522_4diza",
        "colab_type": "text"
      },
      "source": [
        "#5.2 Vectorizamos el conjunto de proceso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLEyyLZ1dtlp",
        "colab_type": "code",
        "outputId": "cd81f6f6-a993-4959-c2ee-2a9da8b653c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Vectorizamos el conjunto de datos de proceso (proces)\n",
        "ts = time.time()\n",
        "process_features = vectorizer.transform(process[2])\n",
        "print (\"Hemos tardado \" + str(time.time() - ts) + \" segundos en vectorizar\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hemos tardado 465.43222522735596 segundos en vectorizar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig_mmi-tKlrf",
        "colab_type": "text"
      },
      "source": [
        "# 6. Creamos el modelo y... lo ejecutamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jArUQyOwKjjW",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "edc07f28-6a98-4a09-bbd4-ba803684bd91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Texto de título predeterminado\n",
        "# Creamos el modelo. Linear Support Vector Machine Classifier\n",
        "model = LinearSVC(max_iter=5000)\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Entrenamos\n",
        "model.fit(training_features, train[\"Categoria\"])\n",
        "\n",
        "# Hacemos una predicción\n",
        "y_pred = model.predict(process_features)\n",
        "\n",
        "#acc = accuracy_score(test[\"Categoria\"], y_pred)\n",
        "\n",
        "#print(\"Accuracy on the BOE dataset: {:.2f}\".format(acc*100))\n",
        "\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11, 11, 11, ..., 11, 20, 19])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibPZByJRMApp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAkio2GIxxmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "i = np.array([[1, \"acuerdo\"],\n",
        "              [2, \"anuncios\"],\n",
        "              [3, \"aprobacion\"],\n",
        "              [4, \"competencias\"],\n",
        "              [5, \"concurso\"],\n",
        "              [6, \"constitucional\"],\n",
        "              [7, \"convenio\"],\n",
        "              [8, \"correccion\"],\n",
        "              [9, \"divisas\"],\n",
        "              [10, \"educacion\"],\n",
        "              [11, \"empleo/oposicion\"],\n",
        "              [12, \"extravio\"],\n",
        "              [13, \"ley\"],\n",
        "              [14, \"nombramientos\"],\n",
        "              [15, \"politica exterior\"],\n",
        "              [16, \"politica interior\"],\n",
        "              [17, \"premios\"],\n",
        "              [18, \"resolucion\"],\n",
        "              [19, \"subasta\"],\n",
        "              [20, \"subvencion\"]])\n",
        "i\n",
        "\n",
        "array = np.hstack((np.vstack((process[1].to_numpy())), np.vstack((y_pred))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNTEqS-tNmoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "\n",
        "np.save(\"./result\", array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyxTIXOfREG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}